{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postId:ID(Post)</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>views</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>How can I do simple machine learning without h...</td>\n",
       "      <td>&lt;p&gt;I've always been interested in machine lear...</td>\n",
       "      <td>8</td>\n",
       "      <td>604.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>What open-source books (or other materials) pr...</td>\n",
       "      <td>&lt;p&gt;As a researcher and instructor, I'm looking...</td>\n",
       "      <td>4</td>\n",
       "      <td>426.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;Not sure if this fits the scope of this SE,...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;One book that's freely available is The Ele...</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>Is Data Science the Same as Data Mining?</td>\n",
       "      <td>&lt;p&gt;I am sure data science as will be discussed...</td>\n",
       "      <td>23</td>\n",
       "      <td>1495.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   postId:ID(Post)                                              title  \\\n",
       "0                5  How can I do simple machine learning without h...   \n",
       "1                7  What open-source books (or other materials) pr...   \n",
       "2                9                                                NaN   \n",
       "3               10                                                NaN   \n",
       "4               14           Is Data Science the Same as Data Mining?   \n",
       "\n",
       "                                                body  score   views  comments  \n",
       "0  <p>I've always been interested in machine lear...      8   604.0         1  \n",
       "1  <p>As a researcher and instructor, I'm looking...      4   426.0         4  \n",
       "2  <p>Not sure if this fits the scope of this SE,...      5     NaN         0  \n",
       "3  <p>One book that's freely available is The Ele...     12     NaN         1  \n",
       "4  <p>I am sure data science as will be discussed...     23  1495.0         1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"import_code/csvs/posts.csv\")\n",
    "# df.drop(['external_author_id','language','publish_date','harvested_date'],axis=1,inplace=True)\n",
    "# df.drop(['tweet_id','article_url','tco1_step1','tco2_step1','tco3_step1'],axis=1,inplace=True)\n",
    "# df.drop(['updates','retweet','new_june_2018','alt_external_id'],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ve always been interested in machine learning but can not figure out one thing about starting',\n",
       " 'as researcher and instructor looking for open source books or similar materials that pro',\n",
       " 'not sure if this fits the scope of this se but here stab at an answer anyway with all',\n",
       " 'one book that freely available is the elements of statistical learning by hastie tibshirani',\n",
       " 'am sure data science as will be discussed in this forum has several synonyms or at least relate',\n",
       " 'in which situations would one system be preferred over the other what are the relative advantage',\n",
       " 'use href to train data and predict clas',\n",
       " 'href rel nofollow libsvm is library for suppor',\n",
       " 'nan',\n",
       " 'lots of people use the term em big data em in rather em commercial em way as means of']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import collections\n",
    "tok = WordPunctTokenizer()\n",
    "pat1 = r'@[A-Za-z0-9_]+'\n",
    "pat2 = r'https?://[^ ]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "www_pat = r'www.[^ ]+'\n",
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "\n",
    "def tweet_cleaner(text):\n",
    "#     soup = BeautifulSoup(text, 'lxml')\n",
    "#     souped = soup.get_text()\n",
    "#     try:\n",
    "#         bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "#     except:\n",
    "#         bom_removed = souped\n",
    "    stripped = re.sub(combined_pat, '', text)\n",
    "    stripped = re.sub(www_pat, '', stripped)\n",
    "    lower_case = stripped.lower()\n",
    "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled)\n",
    "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1]\n",
    "    return (\" \".join(words)).strip()\n",
    "testing = df.body[:10]\n",
    "test_result = []\n",
    "for t in testing:\n",
    "    t = str(t)\n",
    "    #print(type(t))\n",
    "    test_result.append(tweet_cleaner(t))\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/computer/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets 10000 of 39929 has been processed\n",
      "Tweets 20000 of 39929 has been processed\n",
      "Tweets 30000 of 39929 has been processed\n"
     ]
    }
   ],
   "source": [
    "nums = [0,39929]\n",
    "print(\"Cleaning and parsing the tweets...\\n\")\n",
    "clean_tweet_texts = []\n",
    "for i in range(nums[0],nums[1]):\n",
    "    #i = str(i)\n",
    "    if( (i+1)%10000 == 0 ):\n",
    "        print(\"Tweets %d of %d has been processed\" % ( i+1, nums[1] ))\n",
    "    df['body'][i] = str(df['body'][i])\n",
    "    clean_tweet_texts.append(tweet_cleaner(df['body'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_row = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39929\n"
     ]
    }
   ],
   "source": [
    "print(count_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as researcher and instructor looking for open source books or similar materials that pro\n"
     ]
    }
   ],
   "source": [
    "print(clean_tweet_texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
